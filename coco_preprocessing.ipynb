{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Vk_AamzwoN",
        "outputId": "346a5110-d854-4afe-cca3-eab284237e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-25 19:00:32--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.164.113, 3.5.21.203, 16.15.192.185, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.164.113|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  96.5MB/s    in 2.5s    \n",
            "\n",
            "2025-09-25 19:00:35 (96.5 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n",
            "Archive:  annotations_trainval2017.zip\n",
            "  inflating: annotations/instances_train2017.json  \n",
            "  inflating: annotations/instances_val2017.json  \n",
            "  inflating: annotations/captions_train2017.json  \n",
            "  inflating: annotations/captions_val2017.json  \n",
            "  inflating: annotations/person_keypoints_train2017.json  \n",
            "  inflating: annotations/person_keypoints_val2017.json  \n"
          ]
        }
      ],
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!unzip annotations_trainval2017.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ej5OAscQvc0t"
      },
      "outputs": [],
      "source": [
        "train_captions = \"/content/annotations/captions_train2017.json\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Pt_I7eA81TdA"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Captions"
      ],
      "metadata": {
        "id": "34gVb6wfv-_Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RcJd-gMw7rh",
        "outputId": "78e872ba-8723-40a7-f041-f3708a6f5494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['info', 'licenses', 'images', 'annotations'])\n",
            "591753\n",
            "dict_values([203564, 37, 'A bicycle replica with a clock as the front wheel.'])\n"
          ]
        }
      ],
      "source": [
        "with open(train_captions, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(data.keys())\n",
        "print(len(data[\"annotations\"]))\n",
        "print(data[\"annotations\"][0].values())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotations=data[\"annotations\"]\n",
        "print(annotations[0])\n",
        "images=data[\"images\"]\n",
        "print(images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt0Z5v90Y_o0",
        "outputId": "6d15367b-9224-4b82-868e-d57c2b8a1bcf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'image_id': 203564, 'id': 37, 'caption': 'A bicycle replica with a clock as the front wheel.'}\n",
            "{'license': 3, 'file_name': '000000391895.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000391895.jpg', 'height': 360, 'width': 640, 'date_captured': '2013-11-14 11:18:45', 'flickr_url': 'http://farm9.staticflickr.com/8186/8119368305_4e622c8349_z.jpg', 'id': 391895}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pairing"
      ],
      "metadata": {
        "id": "k2QBGOLdwDNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir=\"/content/train2017\"\n",
        "pairs=[]\n",
        "for ann in annotations:\n",
        "    image_id=ann[\"image_id\"]\n",
        "    caption=ann[\"caption\"]\n",
        "    filename = f\"{image_id:012d}.jpg\"\n",
        "    image_path = f\"{image_dir}/{filename}\"\n",
        "    pairs.append((image_path,caption))"
      ],
      "metadata": {
        "id": "kSJtHIoKZRMe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "jYKh2iWDwGZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G46WdjERxUiV"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_caption(caption: str) -> str:\n",
        "    caption = caption.lower()\n",
        "    caption = re.sub(r\"[^a-z0-9\\s]\", \"\", caption)  # keep alphanumeric\n",
        "    return caption.strip()\n",
        "\n",
        "pairs = [(img, clean_caption(cap)) for img, cap in pairs]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "captions = [cap for _, cap in pairs]"
      ],
      "metadata": {
        "id": "vp-xSIx6Z69J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "5wgVBROOwLiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokenized_captions = [word_tokenize(cap) for cap in captions]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPBD1hiUm7u-",
        "outputId": "49a1e06c-1d7a-4108-e4c3-111e2aa8537a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "collapsed": true,
        "id": "aN--4Ai0n2ha",
        "outputId": "8b9176c1-be4f-4568-92cc-802148c4e096"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.2\n",
            "    Uninstalling scipy-1.16.2:\n",
            "      Successfully uninstalled scipy-1.16.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "ec4d9bdf3d5140ea92894cacd96c2623"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ocAau6MpoJWT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Embedding"
      ],
      "metadata": {
        "id": "qIsJtd1jwPyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "w2v_model = Word2Vec(sentences=tokenized_captions, vector_size=300, window=5, min_count=2, workers=4)\n",
        "w2v_model.save(\"coco_word2vec.model\")"
      ],
      "metadata": {
        "id": "K9ub4ca6m9iD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caption_to_vec(caption_tokens, model):\n",
        "    vectors = []\n",
        "    for token in caption_tokens:\n",
        "        if token in model.wv:\n",
        "            vectors.append(model.wv[token])\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(vectors, axis=0)"
      ],
      "metadata": {
        "id": "X8hBVzU8nBBH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "mOwLsy_VRhlk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caption_embeddings = [caption_to_vec(tokens, w2v_model) for tokens in tokenized_captions]\n",
        "\n",
        "print(\"Number of captions:\", len(caption_embeddings))\n",
        "print(\"Shape of first embedding:\", caption_embeddings[0].shape)\n",
        "\n",
        "# Example: show one pair with embedding\n",
        "print(\"Image path:\", pairs[0][0])\n",
        "print(\"Caption:\", pairs[0][1])\n",
        "print(\"Embedding vector (first 10 dims):\", caption_embeddings[0][:10])"
      ],
      "metadata": {
        "id": "8Yh2-0kKndxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecbc4c33-f880-448d-abea-0eacdac3ff1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of captions: 591753\n",
            "Shape of first embedding: (300,)\n",
            "Image path: /content/train2017/000000203564.jpg\n",
            "Caption: a bicycle replica with a clock as the front wheel\n",
            "Embedding vector (first 10 dims): [ 0.14693505 -0.4813532  -0.31320772  0.25158104 -0.11906289  0.33852834\n",
            "  0.00603118 -0.66434944  0.07965587 -0.17264692]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Embeddings"
      ],
      "metadata": {
        "id": "tBnjNTbGQ1HY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "caption_embeddings = np.array(caption_embeddings)\n",
        "np.save(\"caption_embeddings.npy\", caption_embeddings)"
      ],
      "metadata": {
        "id": "hs8CM6U5Qrsj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# caption_embeddings = np.load(\"caption_embeddings.npy\") #load them\n"
      ],
      "metadata": {
        "id": "XVO7I5TjQ3i7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "msDxZPDQQ7Ph"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}